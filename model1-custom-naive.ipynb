{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "935ff793",
   "metadata": {},
   "source": [
    "# Model 1 - Custom Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e365f18d",
   "metadata": {},
   "source": [
    "The first model I will train for this use case is a naive bayes model from scratch as taught in the DeepLearning.AI NLP specialization. I will restrain myself from looking at the provided code and instead, I will try to code this model based solely on the theory. After this model, I will compare the accuracy and performance with a random baseline and two models from the SciKit Learn library (including a Naive Bayes classifyer) to decide on a final model. I will then try to improve the accuracy of the best model by analyzing the errors and performing hyperparameter tuning (if applicable) to achieve optimal results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf74236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import json\n",
    "import os.path\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c239932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path for the processed datasets\n",
    "PATH = \"data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54a88b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a random seed for repeatability\n",
    "random.seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3acf1bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the training dataset\n",
    "hp_sentences = pd.read_csv(f\"{PATH}training_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed632a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A wild-looking old woman dressed all in green ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry was thinking about this time yesterday a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He had been down at Hagrid’s hut, helping him ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“We’re looking for a big, old-fashioned one — ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I forbid you to tell the boy anything!” A brav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  book\n",
       "0  A wild-looking old woman dressed all in green ...     1\n",
       "1  Harry was thinking about this time yesterday a...     1\n",
       "2  He had been down at Hagrid’s hut, helping him ...     1\n",
       "3  “We’re looking for a big, old-fashioned one — ...     1\n",
       "4  I forbid you to tell the boy anything!” A brav...     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 5 rows of the training dataset\n",
    "hp_sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7109405",
   "metadata": {},
   "source": [
    "## Pre-Process Sentences\n",
    "The first step is to pre-process all the sentences by completing the following tasks:\n",
    "1. Lowercase every word\n",
    "2. Remove punctuation\n",
    "3. Remove digits\n",
    "4. Tokenize the sentence\n",
    "5. Remove stop words\n",
    "6. Stem each word\n",
    "\n",
    "This function is held in a separate file for repeatability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e2fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sentence preprocessing function\n",
    "from utils import process_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c40b6919",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence #1:\n",
      "Wormy was here last weekend, I thought he seemed down, but that was probably the news about the McKinnons; I cried all evening when I heard.\n",
      "['wormi', 'last', 'weekend', 'thought', 'seem', 'probabl', 'news', 'mckinnon', 'cri', 'even', 'heard'] \n",
      "\n",
      "\n",
      "Sentence #2:\n",
      "“I don’t care ... I’ll breathe freely again when this tournament’s over, and that’s not until June.\n",
      "['dont', 'care', 'ill', 'breath', 'freeli', 'tournament', 'that', 'june'] \n",
      "\n",
      "\n",
      "Sentence #3:\n",
      "If only Arthur could have got us cars from the Ministry again ... but Fudge wouldn’t let him borrow so much as an empty ink bottle these days... How Muggles can stand traveling without magic ...” But the great black dog gave a joyful bark and gamboled around them, snapping at pigeons, and chasing its own tail.\n",
      "['arthur', 'could', 'got', 'us', 'car', 'ministri', 'fudg', 'wouldnt', 'let', 'borrow', 'much', 'empti', 'ink', 'bottl', 'day', 'muggl', 'stand', 'travel', 'without', 'magic', 'great', 'black', 'dog', 'gave', 'joy', 'bark', 'gambol', 'around', 'snap', 'pigeon', 'chase', 'tail'] \n",
      "\n",
      "\n",
      "Sentence #4:\n",
      "“You need to lie down.\n",
      "['need', 'lie'] \n",
      "\n",
      "\n",
      "Sentence #5:\n",
      "“Look sharp, Tom,” said Slughorn, turning around and finding him still present.\n",
      "['look', 'sharp', 'tom', 'said', 'slughorn', 'turn', 'around', 'find', 'still', 'present'] \n",
      "\n",
      "\n",
      "Sentence #6:\n",
      "They spread their books out in the shade of the beech tree and sat down while Ron talked them through his  first save of the match for what felt like the dozenth time.\n",
      "['spread', 'book', 'shade', 'beech', 'tree', 'sat', 'ron', 'talk', 'first', 'save', 'match', 'felt', 'like', 'dozenth', 'time'] \n",
      "\n",
      "\n",
      "Sentence #7:\n",
      "“But I booked the field!” said Wood, positively spitting with rage.\n",
      "['book', 'field', 'said', 'wood', 'posit', 'spit', 'rage'] \n",
      "\n",
      "\n",
      "Sentence #8:\n",
      "’ They were the same age as we are now.\n",
      "['age'] \n",
      "\n",
      "\n",
      "Sentence #9:\n",
      "“Pointed his wand at me,” Dudley mumbled.\n",
      "['point', 'wand', 'dudley', 'mumbl'] \n",
      "\n",
      "\n",
      "Sentence #10:\n",
      "... C’mon, move in a bit, yeh can pat ’em if yeh want ... give ’em a few o’ these sugar lumps.\n",
      "['cmon', 'move', 'bit', 'yeh', 'pat', 'em', 'yeh', 'want', 'give', 'em', 'sugar', 'lump'] \n",
      "\n",
      "\n",
      "Sentence #11:\n",
      "“Isn’t she with you?” “She lingered in that charming little garden to say hello to the gnomes, such a glorious infestation!\n",
      "['isnt', 'linger', 'charm', 'littl', 'garden', 'say', 'hello', 'gnome', 'gloriou', 'infest'] \n",
      "\n",
      "\n",
      "Sentence #12:\n",
      "“It’s nearly eleven — the match — ” Harry raced up to Gryffindor Tower, collected his Nimbus Two Thousand, and joined the large crowd swarming across the grounds, but his mind was still in the castle along with the bodiless voice, and as he pulled on his scarlet robes in the locker room, his only comfort was that everyone was now outside to watch the game.\n",
      "['nearli', 'eleven', 'match', 'harri', 'race', 'gryffindor', 'tower', 'collect', 'nimbu', 'two', 'thousand', 'join', 'larg', 'crowd', 'swarm', 'across', 'ground', 'mind', 'still', 'castl', 'along', 'bodiless', 'voic', 'pull', 'scarlet', 'robe', 'locker', 'room', 'comfort', 'everyon', 'outsid', 'watch', 'game'] \n",
      "\n",
      "\n",
      "Sentence #13:\n",
      "He sat quite still, anger still surging through him, listening to the frantic thumping of his heart.\n",
      "['sat', 'quit', 'still', 'anger', 'still', 'surg', 'listen', 'frantic', 'thump', 'heart'] \n",
      "\n",
      "\n",
      "Sentence #14:\n",
      "“Yes, first floor, second door on the right, Dai Llewellyn ward.” “Thank you,” said Mrs. Weasley.\n",
      "['ye', 'first', 'floor', 'second', 'door', 'right', 'dai', 'llewellyn', 'ward', 'thank', 'said', 'mr', 'weasley'] \n",
      "\n",
      "\n",
      "Sentence #15:\n",
      "Justin Finch-Fletchley was lying on the floor, rigid and cold, a look of shock frozen on his face, his eyes staring blankly at the ceiling.\n",
      "['justin', 'finchfletchley', 'lie', 'floor', 'rigid', 'cold', 'look', 'shock', 'frozen', 'face', 'eye', 'stare', 'blankli', 'ceil'] \n",
      "\n",
      "\n",
      "Sentence #16:\n",
      "The three of them ran for it; at the door of the boys’ dormitory Harry looked back.\n",
      "['three', 'ran', 'door', 'boy', 'dormitori', 'harri', 'look', 'back'] \n",
      "\n",
      "\n",
      "Sentence #17:\n",
      "“We’ll save our news till tomorrow, shall we?” said Harry.\n",
      "['well', 'save', 'news', 'till', 'tomorrow', 'shall', 'said', 'harri'] \n",
      "\n",
      "\n",
      "Sentence #18:\n",
      "He looked after everything else on the grounds, after all — “Yeh’re goin’ ter win,” Hagrid growled, patting Harry’s shoulder again, so that Harry actually felt himself sink a couple of inches into the soft ground.\n",
      "['look', 'everyth', 'els', 'ground', 'yehr', 'goin', 'ter', 'win', 'hagrid', 'growl', 'pat', 'harri', 'shoulder', 'harri', 'actual', 'felt', 'sink', 'coupl', 'inch', 'soft', 'ground'] \n",
      "\n",
      "\n",
      "Sentence #19:\n",
      "“Well, it was you, really, who gave me the idea, Harry,” she said.\n",
      "['well', 'realli', 'gave', 'idea', 'harri', 'said'] \n",
      "\n",
      "\n",
      "Sentence #20:\n",
      "If Harry Potter goes back to Hogwarts, he will be in mortal danger.” “Why?” said Harry in surprise.\n",
      "['harri', 'potter', 'goe', 'back', 'hogwart', 'mortal', 'danger', 'said', 'harri', 'surpris'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# validate the preprocessing function on 20 random sentences\n",
    "\n",
    "# generate a list of 20 indices from the dataframe\n",
    "indices = random.sample(list(hp_sentences.index), 20)\n",
    "\n",
    "# iterate through the random indices\n",
    "for i, index in enumerate(indices):\n",
    "    \n",
    "    # print the raw sentence and its processed version\n",
    "    raw_sentence = hp_sentences[\"sentence\"].iloc[index]\n",
    "    print(f\"Sentence #{i+1}:\")\n",
    "    print(raw_sentence) \n",
    "    print(process_sentence(raw_sentence), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ed1840",
   "metadata": {},
   "source": [
    "## Create Frequency Dictionary\n",
    "The next step is to create a frequency dictionary that shows how many times each word appears in each book. I also count the total number of words (i.e. tokens) that appear in each book in order to calculate the probabilities using Bayes Theorem. To speed up the process when making changes to the model and when reading the model in other notebooks, I downlaod the generated frequency dictionary to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b77556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_freq_dict (df, process_sentence=process_sentence):\n",
    "    \"\"\"\n",
    "    Creates a frequency dictionary based on the sentences and the book in which they appear.\n",
    "    \n",
    "        Parameters:\n",
    "            df (dataframe): dataframe with the sentences from the Harry Potter books\n",
    "            \n",
    "        Returns:\n",
    "            freq_dict (dict): dictionary with the number of times each word appears in each book\n",
    "    \"\"\"\n",
    "\n",
    "    # initiate dictionary that will hold the word frequencies and number of words per book\n",
    "    freq_dict = {}\n",
    "    book_counts = {}\n",
    "    \n",
    "    # iterate through the rows in the dataframe\n",
    "    for i in df.index:\n",
    "        \n",
    "        # store the book number and processed sentence for the row\n",
    "        book_num = df[\"book\"].iloc[i]\n",
    "        sentence = process_sentence(df[\"sentence\"].iloc[i])\n",
    "        \n",
    "        # iterate through the processed tokens for the row\n",
    "        for token in sentence:\n",
    "            # add 1 to count of words in book\n",
    "            book_counts[str(book_num)] = book_counts.get(str(book_num), 0) + 1\n",
    "            \n",
    "            # add 1 to the existing frequency count for the word or add it to the dictionary if not already there\n",
    "            freq_dict[token+str(book_num)] = freq_dict.get(token+str(book_num), 0) + 1\n",
    "    \n",
    "    # return both dictionaries with the word frequencies and the book counts\n",
    "    return freq_dict, book_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a97a1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the frequency dictionary was not already downloaded\n",
    "if path.exists(f\"{PATH}freq_dict.json\") == False:\n",
    "    \n",
    "    # generate the frequency dictionary and book counts dictionary\n",
    "    freq,book_counts = create_freq_dict(hp_sentences)\n",
    "    \n",
    "    # download the frequency dictionary as a JSON file\n",
    "    with open(f\"{PATH}freq_dict.json\", \"w\") as freq_dict_file:\n",
    "        json.dump(freq, freq_dict_file)\n",
    "    \n",
    "    # download the book counts dictionary as a JSON file\n",
    "    with open(f\"{PATH}book_counts_dict.json\", \"w\") as book_counts_dict_file:\n",
    "        json.dump(book_counts, book_counts_dict_file)\n",
    "        \n",
    "# read the frequency JSON file as a dictionary\n",
    "with open(f\"{PATH}freq_dict.json\", \"r\") as freq_dict_file:\n",
    "    freq = json.load(freq_dict_file)\n",
    "\n",
    "# read the book counts JSON file as a dictionary\n",
    "with open(f\"{PATH}book_counts_dict.json\", \"r\") as book_counts_dict_file:\n",
    "    book_counts = json.load(book_counts_dict_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b918e51b",
   "metadata": {},
   "source": [
    "# Train Model to Predict Book\n",
    "Using the frequency dictionary, it is possible to create a function that predicts the book in which a sentence appears. This is done by processing the sentence into standardized tokens and multiplying together the probability that each token belongs to a book and the probability of a random sentence belonging to that book. The book with the highest probability becomes the prediction. The probability of a token belonging to a book is calculated by dividing the number of times the token appeared in the book by the number of tokens in the book.\n",
    "\n",
    "As the name of the method suggests, this is a naive way of predicting the book as we are assuming that the probability of a token appearing in each book is independent - which it is not. However, it should give us a good enough baseline to compare with other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a14b1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_book (df, sentence, freq, book_counts, process_sentence=process_sentence):\n",
    "    \"\"\"\n",
    "    Predicts the book in which a sentence appears using the Naive Bayes technique.\n",
    "    \n",
    "    Parameters:\n",
    "        df (dataframe): dataframe with the sentences from the Harry Potter books\n",
    "        sentence (string): sentence from a Harry Potter book\n",
    "        \n",
    "    Returns:\n",
    "        book (integer in the range 1-7): Harry Potter book in which the sentence is predicted to appear\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the list of processed tokens for the sentence\n",
    "    tokens = process_sentence(sentence)\n",
    "    \n",
    "    # initiate dictionary that will hold the probability of the sentence appearing in each book\n",
    "    prob_books = {}\n",
    "    \n",
    "    # iterate through the seven book possibilities\n",
    "    for book in range(1, 8):\n",
    "        \n",
    "        # store the total number of sentences in the dataframe and the number of sentences in the iterated book\n",
    "        total_sentences = len(df)\n",
    "        book_sentences = len(df[df[\"book\"] == book])\n",
    "        \n",
    "        # calculate the probability of a random sentence appearing in the iterated book\n",
    "        prob_books[book] = book_sentences / total_sentences\n",
    "        \n",
    "        # iterate through the tokens in the processed sentence\n",
    "        for token in tokens:\n",
    "            \n",
    "            # calculate the probability that the word appears in the iterated book\n",
    "            token_book_prob = freq.get(token + str(book), 0) / book_counts[str(book)]\n",
    "            \n",
    "            # multiply the running probability of the sentence appearing in the iterated book \n",
    "            # by the probability of the word appearing in the book\n",
    "            prob_books[book] *= token_book_prob\n",
    "    \n",
    "    # return the book with the highest probability for the given sentence\n",
    "    return max(prob_books, key=prob_books.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3de0b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column in dataframe with the predicted book\n",
    "hp_sentences[\"predicted_book\"] = hp_sentences[\"sentence\"].apply(lambda sentence: predict_book(hp_sentences, sentence, freq, book_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1fdd66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import accuracy calculation function\n",
    "from utils import calc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebf685fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6355455282904077"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of the classification model on the training dataset\n",
    "calc_accuracy(hp_sentences[\"book\"], hp_sentences[\"predicted_book\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846065c4",
   "metadata": {},
   "source": [
    "An accuracy of 63.5% on the training data for this type of problem is weak, as expected. It is expected that the model will perform worse on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc55590",
   "metadata": {},
   "source": [
    "# Test Model on Validation Set\n",
    "Now that we have trained our model and confirmed that it works, let's measure it's accuracy on unseen data from our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf228816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“She obviously makes more of an effort if you’...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We’ve eaten all our food and you still seem to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please cheer up, Hagrid, we saved the Stone, i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He gave his father a sharp tap on the head wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He kept threatening to tell her what really bi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  book\n",
       "0  “She obviously makes more of an effort if you’...     1\n",
       "1  We’ve eaten all our food and you still seem to...     1\n",
       "2  Please cheer up, Hagrid, we saved the Stone, i...     1\n",
       "3  He gave his father a sharp tap on the head wit...     1\n",
       "4  He kept threatening to tell her what really bi...     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import validation dataset and see first five rows\n",
    "hp_sentences_val = pd.read_csv(f\"{PATH}validation_df.csv\")\n",
    "hp_sentences_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3d3c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column in dataframe with the predicted book\n",
    "hp_sentences_val[\"predicted_book\"] = hp_sentences_val[\"sentence\"].apply(lambda sentence: predict_book(hp_sentences_val, sentence, freq, book_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ad2b6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37163900967255303"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of the classification model on the validation dataset\n",
    "calc_accuracy(hp_sentences_val[\"book\"], hp_sentences_val[\"predicted_book\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc8857",
   "metadata": {},
   "source": [
    "Our model achieved a final accuracy metric of 37.2%, meaning that it is only able to predict the right book in which a sentence appeared every three sentences, approximately. This is a poor result, but is still superior to our random baseline of 1/7 = 14.3%. Next step is to train two other models using the SciKit Learn library and to compare the results of all three models to find the most accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f07abad",
   "metadata": {},
   "source": [
    "# Notebook Complete!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
