{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b36e8d1c",
   "metadata": {},
   "source": [
    "To-do:\n",
    "1. ~~Add random baseline~~\n",
    "2. ~~Add interpretation of confusion matrix and classification report~~\n",
    "3. Compare custom and pre-built naive bayes (count same, visualize per book, correlation)\n",
    "4. Visualize accuracy/book for each model\n",
    "5. Add final interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f8747",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9563b620",
   "metadata": {},
   "source": [
    "This notebook will be used to compare all three models and a random baseline in terms of their accuracy in predicting the book in which a sentence belongs and their efficiency in doing so, measured by the time it takes to make all predictions. The three models will be compared based on the validation dataset. Once a final model is chosen, some hyperparameter tuning and error analysis will be conducted to try to improve its score. Finally, the improved model will be tested against the unseen training dataset to obtain a final accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d614c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from time import time\n",
    "from random import choices\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad0c50",
   "metadata": {},
   "source": [
    "## Import Training, Validation and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811947df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path for the processed datasets\n",
    "PATH = \"data/processed/\"\n",
    "\n",
    "# read the training dataset\n",
    "hp_sentences_train = pd.read_csv(f\"{PATH}training_df.csv\")\n",
    "\n",
    "# read the validation dataset\n",
    "hp_sentences_val = pd.read_csv(f\"{PATH}validation_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a599c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A wild-looking old woman dressed all in green ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry was thinking about this time yesterday a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He had been down at Hagrid’s hut, helping him ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“We’re looking for a big, old-fashioned one — ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I forbid you to tell the boy anything!” A brav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  book\n",
       "0  A wild-looking old woman dressed all in green ...     1\n",
       "1  Harry was thinking about this time yesterday a...     1\n",
       "2  He had been down at Hagrid’s hut, helping him ...     1\n",
       "3  “We’re looking for a big, old-fashioned one — ...     1\n",
       "4  I forbid you to tell the boy anything!” A brav...     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 5 rows of the training dataset\n",
    "hp_sentences_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee02cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“She obviously makes more of an effort if you’...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We’ve eaten all our food and you still seem to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please cheer up, Hagrid, we saved the Stone, i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He gave his father a sharp tap on the head wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He kept threatening to tell her what really bi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  book\n",
       "0  “She obviously makes more of an effort if you’...     1\n",
       "1  We’ve eaten all our food and you still seem to...     1\n",
       "2  Please cheer up, Hagrid, we saved the Stone, i...     1\n",
       "3  He gave his father a sharp tap on the head wit...     1\n",
       "4  He kept threatening to tell her what really bi...     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 5 rows of the validation dataset\n",
    "hp_sentences_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403eee82",
   "metadata": {},
   "source": [
    "## Create a Random Baseline\n",
    "I first want to create a benchmark based on predicting the books randomly to see how much more accurate our models are. To do so, I will calculate the distribution of sentences per book in the training dataset and used this distribution to create a column in the validation dataframe with the random prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2555603a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.0788126140742243,\n",
       " 2: 0.0872794564996958,\n",
       " 3: 0.1150628675725005,\n",
       " 4: 0.18472419387548164,\n",
       " 5: 0.2113668627053336,\n",
       " 6: 0.1458629081322247,\n",
       " 7: 0.17689109714053944}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initiate dictionary that will hold the book distribution from the training dataset\n",
    "book_dist = {}\n",
    "\n",
    "# capture the number of sentences from each book and the total number of sentences in the training set\n",
    "sentences_book = hp_sentences_train[\"book\"].value_counts()\n",
    "total_sentences = sentences_book.sum()\n",
    "\n",
    "# determine the proportion of sentences for each book\n",
    "for book in range(1,8):\n",
    "    book_dist[book] = sentences_book[book] / total_sentences\n",
    "    \n",
    "book_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01bfa9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>book</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“She obviously makes more of an effort if you’...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We’ve eaten all our food and you still seem to...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please cheer up, Hagrid, we saved the Stone, i...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He gave his father a sharp tap on the head wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He kept threatening to tell her what really bi...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  book  Random\n",
       "0  “She obviously makes more of an effort if you’...     1       5\n",
       "1  We’ve eaten all our food and you still seem to...     1       7\n",
       "2  Please cheer up, Hagrid, we saved the Stone, i...     1       5\n",
       "3  He gave his father a sharp tap on the head wit...     1       4\n",
       "4  He kept threatening to tell her what really bi...     1       4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the population (1-7) and weights (proportion/book) of the distribution\n",
    "population = list(book_dist.keys())\n",
    "weights = list(book_dist.values())\n",
    "\n",
    "# calculate the total number of sentences in the validation set\n",
    "validation_count = len(hp_sentences_val)\n",
    "\n",
    "# generate the random prediction for each sentence in the validation set\n",
    "random_predictions = choices(population, weights, k = validation_count)\n",
    "\n",
    "# add the random predictions as a column in the validation dataframe\n",
    "hp_sentences_val[\"Random\"] = random_predictions\n",
    "\n",
    "hp_sentences_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85bfc6",
   "metadata": {},
   "source": [
    "## Re-Train Models\n",
    "Using the same steps used and described in the other two notebooks, I will train the models to be used in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d410d",
   "metadata": {},
   "source": [
    "### Custom Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5841376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the frequency JSON file as a dictionary\n",
    "with open(f\"{PATH}freq_dict.json\", \"r\") as freq_dict_file:\n",
    "    freq = json.load(freq_dict_file)\n",
    "\n",
    "# read the book counts JSON file as a dictionary\n",
    "with open(f\"{PATH}book_counts_dict.json\", \"r\") as book_counts_dict_file:\n",
    "    book_counts = json.load(book_counts_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1220b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sentence preprocessing function\n",
    "from utils import process_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd120cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_book (df, sentence, freq, book_counts, process_sentence=process_sentence):\n",
    "    \"\"\"\n",
    "    Predicts the book in which a sentence appears using the Naive Bayes technique.\n",
    "    \n",
    "    Parameters:\n",
    "        df (dataframe): dataframe with the sentences from the Harry Potter books\n",
    "        sentence (string): sentence from a Harry Potter book\n",
    "        \n",
    "    Returns:\n",
    "        book (integer in the range 1-7): Harry Potter book in which the sentence is predicted to appear\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the list of processed tokens for the sentence\n",
    "    tokens = process_sentence(sentence)\n",
    "    \n",
    "    # initiate dictionary that will hold the probability of the sentence appearing in each book\n",
    "    prob_books = {}\n",
    "    \n",
    "    # iterate through the seven book possibilities\n",
    "    for book in range(1, 8):\n",
    "        \n",
    "        # store the total number of sentences in the dataframe and the number of sentences in the iterated book\n",
    "        total_sentences = len(df)\n",
    "        book_sentences = len(df[df[\"book\"] == book])\n",
    "        \n",
    "        # calculate the probability of a random sentence appearing in the iterated book\n",
    "        prob_books[book] = book_sentences / total_sentences\n",
    "        \n",
    "        # iterate through the tokens in the processed sentence\n",
    "        for token in tokens:\n",
    "            \n",
    "            # calculate the probability that the word appears in the iterated book\n",
    "            token_book_prob = freq.get(token + str(book), 0) / book_counts[str(book)]\n",
    "            \n",
    "            # multiply the running probability of the sentence appearing in the iterated book \n",
    "            # by the probability of the word appearing in the book\n",
    "            prob_books[book] *= token_book_prob\n",
    "    \n",
    "    # return the book with the highest probability for the given sentence\n",
    "    return max(prob_books, key=prob_books.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba76b6ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create new column in dataframe with the predicted book and measure how long it took in seconds\n",
    "start_time = time()\n",
    "hp_sentences_val[\"CustomNB\"] = hp_sentences_val[\"sentence\"].apply(lambda sentence: predict_book(hp_sentences_val, sentence, freq, book_counts))\n",
    "elapsed_time_customNB = time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c5971",
   "metadata": {},
   "source": [
    "### Pre-Built Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "429b3f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline with the three steps required to train the classifier and make predictions\n",
    "hp_classifier_nb = Pipeline([\n",
    "    ('count_vect', CountVectorizer()), # create a word count vector\n",
    "    ('freq_vect', TfidfTransformer()), # normalize the term frequencies\n",
    "    ('classify', MultinomialNB()) # use a Naive Bayes multinomial classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52903cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count_vect', CountVectorizer()),\n",
       "                ('freq_vect', TfidfTransformer()),\n",
       "                ('classify', MultinomialNB())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the sentences in the training dataset\n",
    "hp_classifier_nb.fit(hp_sentences_train[\"sentence\"], hp_sentences_train[\"book\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beb4e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column in dataframe with the predicted book and measure how long it took in seconds\n",
    "start_time = time()\n",
    "hp_sentences_val[\"PrebuiltNB\"] = hp_classifier_nb.predict(hp_sentences_val[\"sentence\"])\n",
    "elapsed_time_prebuiltNB = time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98979c0a",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a949e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline with the three steps required to train the classifier and make predictions\n",
    "hp_classifier_svc = Pipeline([\n",
    "    ('count_vect', CountVectorizer()), # create a word count vector\n",
    "    ('freq_vect', TfidfTransformer()), # normalize the term frequencies\n",
    "    ('classify', LinearSVC()) # use a Linear SVC classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e21d0aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count_vect', CountVectorizer()),\n",
       "                ('freq_vect', TfidfTransformer()), ('classify', LinearSVC())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the sentences in the training dataset\n",
    "hp_classifier_svc.fit(hp_sentences_train[\"sentence\"], hp_sentences_train[\"book\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f7b3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column in dataframe with the predicted book and measure how long it took in seconds\n",
    "start_time = time()\n",
    "hp_sentences_val[\"LinearSVC\"] = hp_classifier_svc.predict(hp_sentences_val[\"sentence\"])\n",
    "elapsed_time_linearSVC = time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd17938",
   "metadata": {},
   "source": [
    "## Evaluate & Compare Models\n",
    "Now that the models have been trained and produced predictions on our validation dataset, it is time to evaluate their results and compare their performances. I will perform the following activities to identify the model to keep and to better understand their behaviors:\n",
    "1. Compare each model's accuracy and efficiency\n",
    "2. Analyze each model's classification report and confusion matrix\n",
    "3. Compare the custom & pre-built Naive Bayes models\n",
    "4. Compare the accuracy per book of each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611e7cb2",
   "metadata": {},
   "source": [
    "### 1. Compare each model's accuracy and efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a651ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import accuracy function\n",
    "from utils import calc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8037ae04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>book</th>\n",
       "      <th>Random</th>\n",
       "      <th>CustomNB</th>\n",
       "      <th>PrebuiltNB</th>\n",
       "      <th>LinearSVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“She obviously makes more of an effort if you’...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We’ve eaten all our food and you still seem to...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please cheer up, Hagrid, we saved the Stone, i...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He gave his father a sharp tap on the head wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He kept threatening to tell her what really bi...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  book  Random  CustomNB  \\\n",
       "0  “She obviously makes more of an effort if you’...     1       5         5   \n",
       "1  We’ve eaten all our food and you still seem to...     1       7         1   \n",
       "2  Please cheer up, Hagrid, we saved the Stone, i...     1       5         1   \n",
       "3  He gave his father a sharp tap on the head wit...     1       4         1   \n",
       "4  He kept threatening to tell her what really bi...     1       4         1   \n",
       "\n",
       "   PrebuiltNB  LinearSVC  \n",
       "0           5          7  \n",
       "1           5          1  \n",
       "2           5          1  \n",
       "3           4          1  \n",
       "4           5          3  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 5 rows of the validation datasets with the predictions from each model\n",
    "hp_sentences_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2fb4b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.151389</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomNB</th>\n",
       "      <td>0.371639</td>\n",
       "      <td>183.883420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrebuiltNB</th>\n",
       "      <td>0.387878</td>\n",
       "      <td>0.233551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.453368</td>\n",
       "      <td>0.220149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Efficiency\n",
       "Random      0.151389         NaN\n",
       "CustomNB    0.371639  183.883420\n",
       "PrebuiltNB  0.387878    0.233551\n",
       "LinearSVC   0.453368    0.220149"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list with the accuracy metric of each model\n",
    "MODEL_NAMES = [\"Random\", \"CustomNB\", \"PrebuiltNB\", \"LinearSVC\"]\n",
    "accuracy_list = []\n",
    "\n",
    "for model in MODEL_NAMES:\n",
    "    accuracy_list.append(calc_accuracy(hp_sentences_val[\"book\"], hp_sentences_val[model]))\n",
    "\n",
    "    \n",
    "# create dataframe with the accuracy and efficiency (time to predict) of each model\n",
    "model_performance_df = pd.DataFrame(data = {\n",
    "                                        \"Accuracy\": accuracy_list,\n",
    "                                        \"Efficiency\": [np.nan, elapsed_time_customNB, elapsed_time_prebuiltNB, elapsed_time_linearSVC]\n",
    "                                    }, index = MODEL_NAMES)\n",
    "\n",
    "# display the dataframe\n",
    "model_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f5175",
   "metadata": {},
   "source": [
    "We can see that the custom model is the least accurate, slightly behind the pre-built Naive bayes model, but is by far the least efficient having took 192 seconds to make all predictions. The two pre-built models took approximately the same amount of time to make their predictions (~0.2 seconds), but the Linear SVC model was the clear winner in terms of accuracy at 45.34%. All models performed significantly better than the random baseline, meaning the models are effective at predicting a book based on the wording used in the sentence. For its high accuracy and efficiency, I will keep the LinearSVC model to complete the project, but I will still spend more time to analyze each model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97021cba",
   "metadata": {},
   "source": [
    "### 2. Analyze each model's classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bfe3dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Naive Bayes\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      0.39      0.22       888\n",
      "           2       0.39      0.25      0.30       983\n",
      "           3       0.41      0.31      0.35      1297\n",
      "           4       0.47      0.38      0.42      2082\n",
      "           5       0.40      0.42      0.41      2382\n",
      "           6       0.40      0.32      0.36      1644\n",
      "           7       0.46      0.43      0.44      1993\n",
      "\n",
      "    accuracy                           0.37     11269\n",
      "   macro avg       0.38      0.36      0.36     11269\n",
      "weighted avg       0.40      0.37      0.38     11269\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 348   61  104  102  132   57   84]\n",
      " [ 203  243   95  120  161   74   87]\n",
      " [ 203   71  408  145  251   92  127]\n",
      " [ 325   85  122  791  406  148  205]\n",
      " [ 483   75  112  225 1010  209  268]\n",
      " [ 321   46   88  133  291  533  232]\n",
      " [ 363   48   76  153  284  214  855]]\n"
     ]
    }
   ],
   "source": [
    "# print classification report for custom naive bayes\n",
    "print(\"Custom Naive Bayes\\n\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(hp_sentences_val[\"book\"], hp_sentences_val[\"CustomNB\"]))\n",
    "\n",
    "# print confusion matrix for custom naive bayes\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(metrics.confusion_matrix(hp_sentences_val[\"book\"], hp_sentences_val[\"CustomNB\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfa1773",
   "metadata": {},
   "source": [
    "* Based on the precision scores per book, we can trust the predictions the most for the fourth book (0.47) and the least for the first book (0.15).\n",
    "* Based on the recall scores per book, the model is most accurate for sentences from the seventh book (0.43) and the least for sentences from the second book (0.25).\n",
    "* When considering both precision and recall through the F1 scores, the model performs best for the seventh book (0.44) and worst for first book (0.22).\n",
    "* The confusion matrix seems to indicate that there is generally the same amount of false positives as false negatives for each book. However, we can notice that there are considerably more false positives than false negatives for the first book which is confirmed by its poor precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ebcb8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Built Naive Bayes\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.01      0.03       888\n",
      "           2       0.74      0.03      0.06       983\n",
      "           3       0.79      0.09      0.15      1297\n",
      "           4       0.47      0.46      0.46      2082\n",
      "           5       0.30      0.83      0.44      2382\n",
      "           6       0.64      0.19      0.29      1644\n",
      "           7       0.52      0.49      0.50      1993\n",
      "\n",
      "    accuracy                           0.39     11269\n",
      "   macro avg       0.58      0.30      0.28     11269\n",
      "weighted avg       0.54      0.39      0.33     11269\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  12    1    6  173  585   14   97]\n",
      " [   0   29    5  197  616   36  100]\n",
      " [   0    1  111  199  839   24  123]\n",
      " [   1    2    3  957  933   22  164]\n",
      " [   2    0    2  192 1984   27  175]\n",
      " [   3    4    6  155  916  307  253]\n",
      " [   1    2    7  164  800   48  971]]\n"
     ]
    }
   ],
   "source": [
    "# print classification report for pre-built naive bayes\n",
    "print(\"Pre-Built Naive Bayes\\n\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(hp_sentences_val[\"book\"], hp_sentences_val[\"PrebuiltNB\"]))\n",
    "\n",
    "# print confusion matrix for pre-built naive bayes\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(metrics.confusion_matrix(hp_sentences_val[\"book\"], hp_sentences_val[\"PrebuiltNB\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb5481",
   "metadata": {},
   "source": [
    "* An initial observation for this model is that unlike the custom Naive Bayes, the pre-built version presents much more imbalance between its precision (avg 0.58) and recall (0.30). In practice, this means that its predictions can generally be trusted more, but it is worst at making a prediction.\n",
    "* The confusion matrix shows that the model performs poorly at predicting the first three books which is confirmed by their recall scores of 0.01, 0.03 and 0.09, respectively.\n",
    "* The model is highly accurate at predicting the fifth book (recall = 0.83), but its predictions can't be trusted because the model over-predicts this book (precision = 0.30). This is likely due to the fact that the fifth book has the most sentences so the model is biased towards it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "666705c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.34      0.36       888\n",
      "           2       0.45      0.31      0.37       983\n",
      "           3       0.42      0.39      0.40      1297\n",
      "           4       0.48      0.50      0.49      2082\n",
      "           5       0.45      0.52      0.48      2382\n",
      "           6       0.44      0.40      0.42      1644\n",
      "           7       0.49      0.53      0.51      1993\n",
      "\n",
      "    accuracy                           0.45     11269\n",
      "   macro avg       0.44      0.43      0.43     11269\n",
      "weighted avg       0.45      0.45      0.45     11269\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 305   49  102  130  130   72  100]\n",
      " [  86  306  107  128  175   82   99]\n",
      " [  97   66  509  174  211   89  151]\n",
      " [  88   85  147 1037  347  161  217]\n",
      " [  98   73  145  306 1232  236  292]\n",
      " [  63   47  111  175  326  656  266]\n",
      " [  61   52   96  205  308  207 1064]]\n"
     ]
    }
   ],
   "source": [
    "# print classification report for linear SVC\n",
    "print(\"Linear SVC\\n\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(hp_sentences_val[\"book\"], hp_sentences_val[\"LinearSVC\"]))\n",
    "\n",
    "# print confusion matrix for linear SVC\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(metrics.confusion_matrix(hp_sentences_val[\"book\"], hp_sentences_val[\"LinearSVC\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81ed331",
   "metadata": {},
   "source": [
    "* Unlike the pre-built Naive Bayes, this model seems more balanced in terms of its precision and recall and performs generally better across books.\n",
    "* Based on the precision scores per book, we can trust the predictions the most for the seventh book (0.49) and the least for the first book (0.38).\n",
    "* Based on the recall scores per book, the model is most accurate for sentences from the seventh book (0.53) and the least for sentences from the second book (0.31).\n",
    "* When considering both precision and recall through the F1 scores, the model performs best for the seventh book (0.51) and worst for first book (0.36).\n",
    "* While the scores are significantly superior for this model, the book rankings for each metrix is the same as the custom Naive Bayes, meaning that the models behave similarly which is not the case for the pre-built Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ba6de8",
   "metadata": {},
   "source": [
    "### 3. Compare the custom & pre-built Naive Bayes models\n",
    "In theory, the custom and pre-built models are based on the same algorithms with a different implementation. Therefore, I would expect them to behave similarly when making predictions. However, as discussed in the previous section, the metrics seem to indicate that the custom Naive Bayes model is more similar to Linear SVC model, although less accurate. I will now explore the relationship between the custom and pre-built NB models more attentively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
