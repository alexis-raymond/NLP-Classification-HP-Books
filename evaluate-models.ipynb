{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b36e8d1c",
   "metadata": {},
   "source": [
    "To-do:\n",
    "1. Add random baseline\n",
    "2. Add interpretation of confusion matrix and classification report\n",
    "3. Compare custom and pre-built naive bayes (count same, visualize per book, correlation)\n",
    "4. Visualize accuracy/book for each model\n",
    "5. Add final interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f8747",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9563b620",
   "metadata": {},
   "source": [
    "This notebook will be used to compare all three models in terms of their accuracy in predicting the book in which a sentence belongs and their efficiency in doing so, measured by the time it takes to make all predictions. The three models will be compared based on the validation dataset. Once a final model is chosen, some hyperparameter tuning and error analysis will be conducted to try to improve its score. Finally, the improved model will be tested against the unseen training dataset to obtain a final accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d614c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from time import time\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad0c50",
   "metadata": {},
   "source": [
    "## Import Training, Validation and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811947df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path for the processed datasets\n",
    "PATH = \"data/processed/\"\n",
    "\n",
    "# read the training dataset\n",
    "hp_sentences_train = pd.read_csv(f\"{PATH}training_df.csv\")\n",
    "\n",
    "# read the validation dataset\n",
    "hp_sentences_val = pd.read_csv(f\"{PATH}validation_df.csv\")\n",
    "\n",
    "# read the testing dataset\n",
    "hp_sentences_test = pd.read_csv(f\"{PATH}testing_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a599c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A wild-looking old woman dressed all in green ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry was thinking about this time yesterday a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He had been down at Hagrid’s hut, helping him ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“We’re looking for a big, old-fashioned one — ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I forbid you to tell the boy anything!” A brav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  book\n",
       "0  A wild-looking old woman dressed all in green ...     1\n",
       "1  Harry was thinking about this time yesterday a...     1\n",
       "2  He had been down at Hagrid’s hut, helping him ...     1\n",
       "3  “We’re looking for a big, old-fashioned one — ...     1\n",
       "4  I forbid you to tell the boy anything!” A brav...     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 5 rows of the training dataset\n",
    "hp_sentences_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee02cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“She obviously makes more of an effort if you’...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We’ve eaten all our food and you still seem to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please cheer up, Hagrid, we saved the Stone, i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He gave his father a sharp tap on the head wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He kept threatening to tell her what really bi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  book\n",
       "0  “She obviously makes more of an effort if you’...     1\n",
       "1  We’ve eaten all our food and you still seem to...     1\n",
       "2  Please cheer up, Hagrid, we saved the Stone, i...     1\n",
       "3  He gave his father a sharp tap on the head wit...     1\n",
       "4  He kept threatening to tell her what really bi...     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 5 rows of the validation dataset\n",
    "hp_sentences_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0decc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excuse me, I’m a prefect!” “How could a troll ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry wasn’t sure he could explain.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There was a tabby cat standing on the corner o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peeves threw the chalk into a bin, which clang...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It didn’t so much as quiver when a car door sl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  book\n",
       "0  Excuse me, I’m a prefect!” “How could a troll ...     1\n",
       "1                Harry wasn’t sure he could explain.     1\n",
       "2  There was a tabby cat standing on the corner o...     1\n",
       "3  Peeves threw the chalk into a bin, which clang...     1\n",
       "4  It didn’t so much as quiver when a car door sl...     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 5 rows of the testing dataset\n",
    "hp_sentences_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85bfc6",
   "metadata": {},
   "source": [
    "## Re-Train Models\n",
    "Using the same steps used and described in the other two notebooks, I will train the models to be used in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d410d",
   "metadata": {},
   "source": [
    "### Custom Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5841376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the frequency JSON file as a dictionary\n",
    "with open(f\"{PATH}freq_dict.json\", \"r\") as freq_dict_file:\n",
    "    freq = json.load(freq_dict_file)\n",
    "\n",
    "# read the book counts JSON file as a dictionary\n",
    "with open(f\"{PATH}book_counts_dict.json\", \"r\") as book_counts_dict_file:\n",
    "    book_counts = json.load(book_counts_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1220b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sentence preprocessing function\n",
    "from utils import process_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cd120cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_book (df, sentence, freq, book_counts, process_sentence=process_sentence):\n",
    "    \"\"\"\n",
    "    Predicts the book in which a sentence appears using the Naive Bayes technique.\n",
    "    \n",
    "    Parameters:\n",
    "        df (dataframe): dataframe with the sentences from the Harry Potter books\n",
    "        sentence (string): sentence from a Harry Potter book\n",
    "        \n",
    "    Returns:\n",
    "        book (integer in the range 1-7): Harry Potter book in which the sentence is predicted to appear\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the list of processed tokens for the sentence\n",
    "    tokens = process_sentence(sentence)\n",
    "    \n",
    "    # initiate dictionary that will hold the probability of the sentence appearing in each book\n",
    "    prob_books = {}\n",
    "    \n",
    "    # iterate through the seven book possibilities\n",
    "    for book in range(1, 8):\n",
    "        \n",
    "        # store the total number of sentences in the dataframe and the number of sentences in the iterated book\n",
    "        total_sentences = len(df)\n",
    "        book_sentences = len(df[df[\"book\"] == book])\n",
    "        \n",
    "        # calculate the probability of a random sentence appearing in the iterated book\n",
    "        prob_books[book] = book_sentences / total_sentences\n",
    "        \n",
    "        # iterate through the tokens in the processed sentence\n",
    "        for token in tokens:\n",
    "            \n",
    "            # calculate the probability that the word appears in the iterated book\n",
    "            token_book_prob = freq.get(token + str(book), 0) / book_counts[str(book)]\n",
    "            \n",
    "            # multiply the running probability of the sentence appearing in the iterated book \n",
    "            # by the probability of the word appearing in the book\n",
    "            prob_books[book] *= token_book_prob\n",
    "    \n",
    "    # return the book with the highest probability for the given sentence\n",
    "    return max(prob_books, key=prob_books.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba76b6ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create new column in dataframe with the predicted book and measure how long it took in seconds\n",
    "start_time = time()\n",
    "hp_sentences_val[\"CustomNB\"] = hp_sentences_val[\"sentence\"].apply(lambda sentence: predict_book(hp_sentences_val, sentence, freq, book_counts))\n",
    "elapsed_time_customNB = time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c5971",
   "metadata": {},
   "source": [
    "### Pre-Built Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "429b3f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline with the three steps required to train the classifier and make predictions\n",
    "hp_classifier_nb = Pipeline([\n",
    "    ('count_vect', CountVectorizer()), # create a word count vector\n",
    "    ('freq_vect', TfidfTransformer()), # normalize the term frequencies\n",
    "    ('classify', MultinomialNB()) # use a Naive Bayes multinomial classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52903cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count_vect', CountVectorizer()),\n",
       "                ('freq_vect', TfidfTransformer()),\n",
       "                ('classify', MultinomialNB())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the sentences in the training dataset\n",
    "hp_classifier_nb.fit(hp_sentences_train[\"sentence\"], hp_sentences_train[\"book\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beb4e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column in dataframe with the predicted book and measure how long it took in seconds\n",
    "start_time = time()\n",
    "hp_sentences_val[\"PrebuiltNB\"] = hp_classifier_nb.predict(hp_sentences_val[\"sentence\"])\n",
    "elapsed_time_prebuiltNB = time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98979c0a",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a949e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline with the three steps required to train the classifier and make predictions\n",
    "hp_classifier_svc = Pipeline([\n",
    "    ('count_vect', CountVectorizer()), # create a word count vector\n",
    "    ('freq_vect', TfidfTransformer()), # normalize the term frequencies\n",
    "    ('classify', LinearSVC()) # use a Linear SVC classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e21d0aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count_vect', CountVectorizer()),\n",
       "                ('freq_vect', TfidfTransformer()), ('classify', LinearSVC())])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the sentences in the training dataset\n",
    "hp_classifier_svc.fit(hp_sentences_train[\"sentence\"], hp_sentences_train[\"book\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f7b3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column in dataframe with the predicted book and measure how long it took in seconds\n",
    "start_time = time()\n",
    "hp_sentences_val[\"LinearSVC\"] = hp_classifier_svc.predict(hp_sentences_val[\"sentence\"])\n",
    "elapsed_time_linearSVC = time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd17938",
   "metadata": {},
   "source": [
    "## Evaluate & Compare Models\n",
    "Now that the models have been trained and produced predictions on our validation dataset, it is time to evaluate their results and compare their performances. I will perform the following activities to identify the model to keep and to better understand their behaviors:\n",
    "1. Compare each model's accuracy and efficiency\n",
    "2. Analyze each model's classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611e7cb2",
   "metadata": {},
   "source": [
    "### 1. Compare each model's accuracy and efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a651ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import accuracy function\n",
    "from utils import calc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8037ae04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>book</th>\n",
       "      <th>CustomNB</th>\n",
       "      <th>PrebuiltNB</th>\n",
       "      <th>LinearSVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“She obviously makes more of an effort if you’...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We’ve eaten all our food and you still seem to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please cheer up, Hagrid, we saved the Stone, i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He gave his father a sharp tap on the head wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He kept threatening to tell her what really bi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  book  CustomNB  \\\n",
       "0  “She obviously makes more of an effort if you’...     1         5   \n",
       "1  We’ve eaten all our food and you still seem to...     1         1   \n",
       "2  Please cheer up, Hagrid, we saved the Stone, i...     1         1   \n",
       "3  He gave his father a sharp tap on the head wit...     1         1   \n",
       "4  He kept threatening to tell her what really bi...     1         1   \n",
       "\n",
       "   PrebuiltNB  LinearSVC  \n",
       "0           5          7  \n",
       "1           5          1  \n",
       "2           5          1  \n",
       "3           4          1  \n",
       "4           5          3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 5 rows of the validation datasets with the predictions from each model\n",
    "hp_sentences_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2fb4b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CustomNB</th>\n",
       "      <td>0.371639</td>\n",
       "      <td>192.953710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrebuiltNB</th>\n",
       "      <td>0.387878</td>\n",
       "      <td>0.226398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.453368</td>\n",
       "      <td>0.214321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Efficiency\n",
       "CustomNB    0.371639  192.953710\n",
       "PrebuiltNB  0.387878    0.226398\n",
       "LinearSVC   0.453368    0.214321"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list with the accuracy metric of each model\n",
    "MODEL_NAMES = [\"CustomNB\", \"PrebuiltNB\", \"LinearSVC\"]\n",
    "accuracy_list = []\n",
    "\n",
    "for model in MODEL_NAMES:\n",
    "    accuracy_list.append(calc_accuracy(hp_sentences_val[\"book\"], hp_sentences_val[model]))\n",
    "\n",
    "    \n",
    "# create dataframe with the accuracy and efficiency (time to predict) of each model\n",
    "model_performance_df = pd.DataFrame(data = {\n",
    "                                        \"Accuracy\": accuracy_list,\n",
    "                                        \"Efficiency\": [elapsed_time_customNB, elapsed_time_prebuiltNB, elapsed_time_linearSVC]\n",
    "                                    }, index = MODEL_NAMES)\n",
    "\n",
    "# display the dataframe\n",
    "model_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f5175",
   "metadata": {},
   "source": [
    "We can see that the custom model is the least accurate, slightly behind the pre-built Naive bayes model, but is by far the least efficient having took 192 seconds to make all predictions. The two pre-built models took approximately the same amount of time to make their predictions (~0.2 seconds), but the Linear SVC model was the clear winner in terms of accuracy at 45.34%. Therefore, this is the model I will keep to complete the project, but I will still spend more time to analyze each model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97021cba",
   "metadata": {},
   "source": [
    "### 2. Analyze each model's classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bfe3dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Naive Bayes\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      0.39      0.22       888\n",
      "           2       0.39      0.25      0.30       983\n",
      "           3       0.41      0.31      0.35      1297\n",
      "           4       0.47      0.38      0.42      2082\n",
      "           5       0.40      0.42      0.41      2382\n",
      "           6       0.40      0.32      0.36      1644\n",
      "           7       0.46      0.43      0.44      1993\n",
      "\n",
      "    accuracy                           0.37     11269\n",
      "   macro avg       0.38      0.36      0.36     11269\n",
      "weighted avg       0.40      0.37      0.38     11269\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 348   61  104  102  132   57   84]\n",
      " [ 203  243   95  120  161   74   87]\n",
      " [ 203   71  408  145  251   92  127]\n",
      " [ 325   85  122  791  406  148  205]\n",
      " [ 483   75  112  225 1010  209  268]\n",
      " [ 321   46   88  133  291  533  232]\n",
      " [ 363   48   76  153  284  214  855]]\n"
     ]
    }
   ],
   "source": [
    "# print classification report for custom naive bayes\n",
    "print(\"Custom Naive Bayes\\n\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(hp_sentences_val[\"book\"], hp_sentences_val[\"CustomNB\"]))\n",
    "\n",
    "# print confusion matrix for custom naive bayes\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(metrics.confusion_matrix(hp_sentences_val[\"book\"], hp_sentences_val[\"CustomNB\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ebcb8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Built Naive Bayes\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.01      0.03       888\n",
      "           2       0.74      0.03      0.06       983\n",
      "           3       0.79      0.09      0.15      1297\n",
      "           4       0.47      0.46      0.46      2082\n",
      "           5       0.30      0.83      0.44      2382\n",
      "           6       0.64      0.19      0.29      1644\n",
      "           7       0.52      0.49      0.50      1993\n",
      "\n",
      "    accuracy                           0.39     11269\n",
      "   macro avg       0.58      0.30      0.28     11269\n",
      "weighted avg       0.54      0.39      0.33     11269\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  12    1    6  173  585   14   97]\n",
      " [   0   29    5  197  616   36  100]\n",
      " [   0    1  111  199  839   24  123]\n",
      " [   1    2    3  957  933   22  164]\n",
      " [   2    0    2  192 1984   27  175]\n",
      " [   3    4    6  155  916  307  253]\n",
      " [   1    2    7  164  800   48  971]]\n"
     ]
    }
   ],
   "source": [
    "# print classification report for pre-built naive bayes\n",
    "print(\"Pre-Built Naive Bayes\\n\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(hp_sentences_val[\"book\"], hp_sentences_val[\"PrebuiltNB\"]))\n",
    "\n",
    "# print confusion matrix for pre-built naive bayes\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(metrics.confusion_matrix(hp_sentences_val[\"book\"], hp_sentences_val[\"PrebuiltNB\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "666705c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.34      0.36       888\n",
      "           2       0.45      0.31      0.37       983\n",
      "           3       0.42      0.39      0.40      1297\n",
      "           4       0.48      0.50      0.49      2082\n",
      "           5       0.45      0.52      0.48      2382\n",
      "           6       0.44      0.40      0.42      1644\n",
      "           7       0.49      0.53      0.51      1993\n",
      "\n",
      "    accuracy                           0.45     11269\n",
      "   macro avg       0.44      0.43      0.43     11269\n",
      "weighted avg       0.45      0.45      0.45     11269\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 305   49  102  130  130   72  100]\n",
      " [  86  306  107  128  175   82   99]\n",
      " [  97   66  509  174  211   89  151]\n",
      " [  88   85  147 1037  347  161  217]\n",
      " [  98   73  145  306 1232  236  292]\n",
      " [  63   47  111  175  326  656  266]\n",
      " [  61   52   96  205  308  207 1064]]\n"
     ]
    }
   ],
   "source": [
    "# print classification report for linear SVC\n",
    "print(\"Linear SVC\\n\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(hp_sentences_val[\"book\"], hp_sentences_val[\"LinearSVC\"]))\n",
    "\n",
    "# print confusion matrix for linear SVC\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(metrics.confusion_matrix(hp_sentences_val[\"book\"], hp_sentences_val[\"LinearSVC\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
